{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7MZdUojen2e",
        "outputId": "b2b2bad0-6ccf-4bdb-c611-f838163bffa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (1.26.16)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchdata) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchdata) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchdata) (16.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchdata) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchdata) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import multi30k, Multi30k\n",
        "from typing import Iterable, List"
      ],
      "metadata": {
        "id": "3yv-gjpjmCMM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
        "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\""
      ],
      "metadata": {
        "id": "-7HlblR084Nw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SRC_LANGUAGE = 'de'\n",
        "TGT_LANGUAGE = 'en'"
      ],
      "metadata": {
        "id": "Qe818vDG9whB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_transform = {}\n",
        "vocab_transform = {}"
      ],
      "metadata": {
        "id": "BcQKDT1_-ACF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu1sUGYl-E0d",
        "outputId": "a831a262-2792-4384-974b-a0efcfa5e684"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install portalocker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e-D7lhlCw8z",
        "outputId": "7873b193-ffa0-4e12-95c0-ab8816217bb1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (2.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dP67asJ-vMl",
        "outputId": "86da8bd5-44b4-4783-aba9-d16fa1616d23"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-08-03 07:44:54.056200: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-03 07:44:55.195966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-08-03 07:44:56.553455: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-03 07:44:56.553892: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-03 07:44:56.554091: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "2023-08-03 07:45:09.717446: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-03 07:45:10.770347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-08-03 07:45:12.147305: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-03 07:45:12.147882: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-08-03 07:45:12.148060: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Collecting de-core-news-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.6.0/de_core_news_sm-3.6.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.6.0) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->de-core-news-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='de_core_news_sm')\n",
        "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')"
      ],
      "metadata": {
        "id": "niaLAYor-j8V"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_transform"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stjC90Aa-pIT",
        "outputId": "d670d26e-fc46-42ac-e989-ca348c534f48"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'de': functools.partial(<function _spacy_tokenize at 0x7a930cc8a710>, spacy=<spacy.lang.de.German object at 0x7a923cd9ff40>),\n",
              " 'en': functools.partial(<function _spacy_tokenize at 0x7a930cc8a710>, spacy=<spacy.lang.en.English object at 0x7a93079fd660>)}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform[language](data_sample[language_index[language]])"
      ],
      "metadata": {
        "id": "KZvXVbnh-7CK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=1,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True)"
      ],
      "metadata": {
        "id": "Ie3ORgdqBEPF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_transform['en'].get_stoi() # mapping of tokens to indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4PnjdeIDZmz",
        "outputId": "c55e5d6f-5c73-44a0-87a0-e90222d8881f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'zips': 10834,\n",
              " 'zippered': 10833,\n",
              " 'youngster': 10832,\n",
              " 'yong': 10831,\n",
              " 'yielding': 10830,\n",
              " 'yawns': 10827,\n",
              " 'yawing': 10826,\n",
              " 'yak': 10825,\n",
              " 'yacht': 10824,\n",
              " 'wuth': 10822,\n",
              " 'writhing': 10820,\n",
              " 'wristwatch': 10818,\n",
              " 'wrecks': 10814,\n",
              " 'wrecked': 10813,\n",
              " 'wrappers': 10812,\n",
              " 'wrangled': 10810,\n",
              " 'worshiping': 10807,\n",
              " 'worshipers': 10806,\n",
              " 'woodsy': 10802,\n",
              " 'wonders': 10801,\n",
              " 'wonderment': 10800,\n",
              " 'wonder': 10798,\n",
              " 'won': 10797,\n",
              " 'wmoan': 10794,\n",
              " 'wizards': 10793,\n",
              " 'witnessing': 10792,\n",
              " 'witnessed': 10791,\n",
              " 'wireless': 10785,\n",
              " 'windy': 10779,\n",
              " 'windsurfing': 10777,\n",
              " 'wildly': 10773,\n",
              " 'wieners': 10769,\n",
              " 'whitewater': 10767,\n",
              " 'whites': 10766,\n",
              " 'whiteboard': 10765,\n",
              " 'whistling': 10764,\n",
              " 'whips': 10762,\n",
              " 'whine': 10761,\n",
              " 'whereas': 10759,\n",
              " 'wheelers': 10758,\n",
              " 'whatever': 10756,\n",
              " 'whales': 10755,\n",
              " 'went': 10753,\n",
              " 'wells': 10752,\n",
              " 'welders': 10751,\n",
              " 'weld': 10750,\n",
              " 'weiner': 10749,\n",
              " 'weightlifting': 10748,\n",
              " 'weighs': 10746,\n",
              " 'weighed': 10745,\n",
              " 'week': 10743,\n",
              " 'wedge': 10742,\n",
              " 'website': 10740,\n",
              " 'webpage': 10739,\n",
              " 'weating': 10737,\n",
              " 'weak': 10735,\n",
              " 'waterskis': 10733,\n",
              " 'waterskiis': 10732,\n",
              " 'waste': 10729,\n",
              " 'warplane': 10728,\n",
              " 'warped': 10727,\n",
              " 'warmer': 10726,\n",
              " 'warily': 10725,\n",
              " 'wards': 10724,\n",
              " 'wardrobe': 10723,\n",
              " 'wandering': 10721,\n",
              " 'wander': 10720,\n",
              " 'waltzing': 10719,\n",
              " 'walmart': 10718,\n",
              " 'wallpaper': 10717,\n",
              " 'waling': 10715,\n",
              " 'wake': 10713,\n",
              " 'waiters': 10712,\n",
              " 'waffles': 10710,\n",
              " 'vulture': 10708,\n",
              " 'vs': 10707,\n",
              " 'volunteering': 10704,\n",
              " 'volleys': 10703,\n",
              " 'volley': 10702,\n",
              " 'vocals': 10699,\n",
              " 'vocal': 10698,\n",
              " 'vocabulary': 10697,\n",
              " 'viz': 10696,\n",
              " 'visits': 10694,\n",
              " 'visitors': 10693,\n",
              " 'vise': 10690,\n",
              " 'violinists': 10688,\n",
              " 'violation': 10687,\n",
              " 'vineyard': 10686,\n",
              " 'vines': 10685,\n",
              " 'vikings': 10684,\n",
              " 'viking': 10683,\n",
              " 'vigil': 10682,\n",
              " 'viewpoint': 10681,\n",
              " 'viewfinders': 10680,\n",
              " 'viewed': 10679,\n",
              " 'viewable': 10678,\n",
              " 'vietnamese': 10677,\n",
              " 'vie': 10676,\n",
              " 'videocameras': 10674,\n",
              " 'vicinity': 10673,\n",
              " 'vials': 10671,\n",
              " 'veterans': 10670,\n",
              " 'velveeta': 10665,\n",
              " 'velodrome': 10664,\n",
              " 'vaults': 10662,\n",
              " 'vaulter': 10661,\n",
              " 'vat': 10659,\n",
              " 'vandalized': 10656,\n",
              " 'vampire': 10655,\n",
              " 'valve': 10654,\n",
              " 'vaguely': 10653,\n",
              " 'vacationing': 10652,\n",
              " 'vac': 10651,\n",
              " 'utilizing': 10649,\n",
              " 'utensil': 10648,\n",
              " 'usage': 10647,\n",
              " 'urinating': 10644,\n",
              " 'urging': 10643,\n",
              " 'urged': 10641,\n",
              " 'upstairs': 10640,\n",
              " 'uplifted': 10639,\n",
              " 'unwrapping': 10638,\n",
              " 'unwary': 10636,\n",
              " 'untangling': 10635,\n",
              " 'unsure': 10634,\n",
              " 'unscrewing': 10632,\n",
              " 'unrecognizable': 10630,\n",
              " 'unraveling': 10629,\n",
              " 'unlocking': 10625,\n",
              " 'unloads': 10624,\n",
              " 'units': 10621,\n",
              " 'unitard': 10619,\n",
              " 'unidentifiable': 10617,\n",
              " 'unfortunate': 10614,\n",
              " 'unexcited': 10612,\n",
              " 'unenthusiastic': 10610,\n",
              " 'undone': 10609,\n",
              " 'uncrowded': 10608,\n",
              " 'uncovering': 10607,\n",
              " 'uncooked': 10606,\n",
              " 'unclear': 10603,\n",
              " 'unable': 10602,\n",
              " 'typewriter': 10598,\n",
              " 'twos': 10597,\n",
              " 'twelve': 10594,\n",
              " 'tuxes': 10592,\n",
              " 'tussle': 10591,\n",
              " 'tusks': 10590,\n",
              " 'turntables': 10588,\n",
              " 'turnaround': 10587,\n",
              " 'tunics': 10585,\n",
              " 'tummy': 10584,\n",
              " 'tumble': 10582,\n",
              " 'tugboat': 10581,\n",
              " 'tubular': 10579,\n",
              " 'trudging': 10575,\n",
              " 'trudge': 10574,\n",
              " 'trousers': 10572,\n",
              " 'troupe': 10571,\n",
              " 'trolly': 10570,\n",
              " 'triumphantly': 10567,\n",
              " 'tripods': 10566,\n",
              " 'trinket': 10565,\n",
              " 'tribute': 10560,\n",
              " 'tribesman': 10559,\n",
              " 'trellis': 10558,\n",
              " 'trek': 10557,\n",
              " 'treefilled': 10556,\n",
              " 'treated': 10555,\n",
              " 'treadmills': 10554,\n",
              " 'treadle': 10553,\n",
              " 'travelers': 10549,\n",
              " 'traveler': 10548,\n",
              " 'traps': 10545,\n",
              " 'trapeze': 10544,\n",
              " 'transvestite': 10543,\n",
              " 'transparent': 10541,\n",
              " 'translucent': 10540,\n",
              " 'transformers': 10539,\n",
              " 'transfer': 10538,\n",
              " 'tranquil': 10537,\n",
              " 'trampled': 10536,\n",
              " 'trainer': 10535,\n",
              " 'trailers': 10533,\n",
              " 'trafficked': 10532,\n",
              " 'tradition': 10531,\n",
              " 'tracker': 10529,\n",
              " 'tracked': 10528,\n",
              " 'toweling': 10526,\n",
              " 'tough': 10524,\n",
              " 'totter': 10523,\n",
              " 'totem': 10522,\n",
              " 'torwards': 10521,\n",
              " 'torii': 10518,\n",
              " 'toppings': 10516,\n",
              " 'tons': 10512,\n",
              " 'tombstone': 10510,\n",
              " 'toenail': 10507,\n",
              " 'toed': 10506,\n",
              " 'timidly': 10499,\n",
              " 'till': 10495,\n",
              " 'tiling': 10494,\n",
              " 'tiki': 10493,\n",
              " 'tightropes': 10492,\n",
              " 'tickling': 10491,\n",
              " 'thrower': 10488,\n",
              " 'threes': 10486,\n",
              " 'threads': 10485,\n",
              " 'thoughtfully': 10483,\n",
              " 'thoughtful': 10482,\n",
              " 'then': 10476,\n",
              " 'thck': 10475,\n",
              " 'texture': 10473,\n",
              " 'textiles': 10472,\n",
              " 'tether': 10471,\n",
              " 'terriers': 10468,\n",
              " 'tented': 10467,\n",
              " 'tentatively': 10466,\n",
              " 'tended': 10465,\n",
              " 'template': 10464,\n",
              " 'teepee': 10459,\n",
              " 'technicians': 10458,\n",
              " 'tumbles': 10583,\n",
              " 'teasing': 10456,\n",
              " 'taupe': 10452,\n",
              " 'taughter': 10451,\n",
              " 'tatooed': 10450,\n",
              " 'tastes': 10449,\n",
              " 'tassels': 10448,\n",
              " 'tarps': 10447,\n",
              " 'wonderful': 10799,\n",
              " 'tapestry': 10444,\n",
              " 'tanks': 10443,\n",
              " 'tango': 10442,\n",
              " 'tangled': 10441,\n",
              " 'tamed': 10438,\n",
              " 'tame': 10437,\n",
              " 'tak': 10435,\n",
              " 'tails': 10434,\n",
              " 'tailgate': 10433,\n",
              " 'tactical': 10429,\n",
              " 'tabletop': 10427,\n",
              " 'synthesizer': 10425,\n",
              " 'sync': 10423,\n",
              " 'symmetry': 10422,\n",
              " 'swordfish': 10420,\n",
              " 'swordfight': 10419,\n",
              " 'swooping': 10418,\n",
              " 'swishing': 10416,\n",
              " 'trikes': 10563,\n",
              " 'swirling': 10415,\n",
              " 'swirl': 10414,\n",
              " 'swipes': 10413,\n",
              " 'swifter': 10410,\n",
              " 'swept': 10407,\n",
              " 'sweeter': 10406,\n",
              " 'sweats': 10403,\n",
              " 'swatted': 10401,\n",
              " 'swap': 10400,\n",
              " 'swans': 10399,\n",
              " 'swamp': 10398,\n",
              " 'surrounds': 10394,\n",
              " 'surronded': 10393,\n",
              " 'surgeon': 10391,\n",
              " 'surfboarding': 10390,\n",
              " 'sure': 10389,\n",
              " 'supporters': 10388,\n",
              " 'supple': 10387,\n",
              " 'supervises': 10385,\n",
              " 'supervised': 10384,\n",
              " 'superstore': 10382,\n",
              " 'superhero': 10381,\n",
              " 'sunshade': 10380,\n",
              " 'sunlit': 10379,\n",
              " 'sunflowers': 10378,\n",
              " 'summertime': 10375,\n",
              " 'suites': 10374,\n",
              " 'successfully': 10372,\n",
              " 'suburb': 10370,\n",
              " 'styrofoam': 10368,\n",
              " 'stylus': 10367,\n",
              " 'stumbles': 10365,\n",
              " 'stumbled': 10364,\n",
              " 'stuffs': 10363,\n",
              " 'stuffing': 10362,\n",
              " 'stucco': 10361,\n",
              " 'stubble': 10360,\n",
              " 'struck': 10359,\n",
              " 'stroking': 10357,\n",
              " 'strives': 10355,\n",
              " 'stripy': 10354,\n",
              " 'stripping': 10353,\n",
              " 'stripey': 10352,\n",
              " 'strength': 10350,\n",
              " 'streetcar': 10349,\n",
              " 'streamer': 10347,\n",
              " 'strawberries': 10345,\n",
              " 'strangely': 10344,\n",
              " 'strainer': 10343,\n",
              " 'straddling': 10342,\n",
              " 'stormy': 10340,\n",
              " 'stored': 10339,\n",
              " 'stooping': 10337,\n",
              " 'stood': 10336,\n",
              " 'stoney': 10335,\n",
              " 'stoned': 10334,\n",
              " 'stomped': 10333,\n",
              " 'stoking': 10331,\n",
              " 'stocky': 10330,\n",
              " 'stocks': 10329,\n",
              " 'stitch': 10327,\n",
              " 'stir': 10326,\n",
              " 'stiletto': 10325,\n",
              " 'stickers': 10324,\n",
              " 'stewardess': 10323,\n",
              " 'stepped': 10321,\n",
              " 'stencil': 10320,\n",
              " 'steamed': 10319,\n",
              " 'steak': 10318,\n",
              " 'steadying': 10317,\n",
              " 'staue': 10314,\n",
              " 'stapling': 10310,\n",
              " 'standard': 10306,\n",
              " 'stances': 10305,\n",
              " 'stallions': 10301,\n",
              " 'staffordshire': 10298,\n",
              " 'stabs': 10296,\n",
              " 'stables': 10295,\n",
              " 'stabilize': 10294,\n",
              " 'stabbed': 10293,\n",
              " 'squirt': 10292,\n",
              " 'squid': 10291,\n",
              " 'squeezes': 10290,\n",
              " 'squeals': 10289,\n",
              " 'squatted': 10288,\n",
              " 'stadning': 10297,\n",
              " 'squaring': 10287,\n",
              " 'squabble': 10286,\n",
              " 'sprawled': 10283,\n",
              " 'spouts': 10282,\n",
              " 'spotters': 10281,\n",
              " 'spooning': 10278,\n",
              " 'spool': 10276,\n",
              " 'spoof': 10275,\n",
              " 'sponges': 10274,\n",
              " 'terrorizes': 10470,\n",
              " 'boutique': 5086,\n",
              " 'from': 67,\n",
              " 'jumpsuit': 1301,\n",
              " 'ranch': 9806,\n",
              " 'boaters': 5075,\n",
              " 'blues': 5073,\n",
              " 'bloom': 5071,\n",
              " 'blinds': 5069,\n",
              " 'blind': 5068,\n",
              " 'rabbit': 3736,\n",
              " 'blankly': 5066,\n",
              " 'beggar': 7713,\n",
              " 'bits': 5061,\n",
              " 'ancient': 2741,\n",
              " 'generator': 8763,\n",
              " 'sheepdog': 4566,\n",
              " 'frowning': 5393,\n",
              " 'bins': 5059,\n",
              " 'dunes': 3539,\n",
              " 'variety': 2697,\n",
              " 'beauty': 5051,\n",
              " 'batting': 5047,\n",
              " 'railing': 612,\n",
              " 'battery': 5046,\n",
              " 'kung': 9144,\n",
              " 'bandage': 5039,\n",
              " 'pullover': 9772,\n",
              " 'bagpipers': 5033,\n",
              " 'bagel': 5032,\n",
              " 'mechanic': 3645,\n",
              " 'bad': 5031,\n",
              " 'attended': 5019,\n",
              " 'glancing': 5409,\n",
              " 'showers': 5921,\n",
              " 'gulls': 8854,\n",
              " 'attaching': 5015,\n",
              " 'mom': 1356,\n",
              " 'aside': 5009,\n",
              " 'Islamic': 4818,\n",
              " 'Organ': 6999,\n",
              " 'answer': 4997,\n",
              " 'landmarks': 9159,\n",
              " 'animatedly': 4993,\n",
              " 'sunbathes': 10377,\n",
              " 'amplifier': 4991,\n",
              " 'Zoo': 7449,\n",
              " 'Chef': 6439,\n",
              " 'always': 4988,\n",
              " 'altitude': 4987,\n",
              " 'again': 4977,\n",
              " 'chaps': 7960,\n",
              " 'adventure': 4974,\n",
              " 'admire': 4972,\n",
              " 'Foursome': 6645,\n",
              " 'logo': 2600,\n",
              " 'numerals': 9439,\n",
              " 'Brick': 4757,\n",
              " 'Killer': 6828,\n",
              " 'collides': 8052,\n",
              " 'attired': 4054,\n",
              " 'Veteran': 4947,\n",
              " 'VW': 4945,\n",
              " 'wintry': 10782,\n",
              " 'ICE': 6761,\n",
              " 'UFC': 4943,\n",
              " 'knight': 4338,\n",
              " 'large': 62,\n",
              " 'Their': 4934,\n",
              " 'towarn': 10525,\n",
              " 'programs': 5782,\n",
              " 'shorts': 153,\n",
              " 'Swimmer': 4927,\n",
              " 'shipping': 10091,\n",
              " 'Sunday': 4924,\n",
              " 'ME': 6883,\n",
              " 'Story': 4921,\n",
              " 'para': 9540,\n",
              " 'Segway': 4901,\n",
              " 'Samsung': 4896,\n",
              " 'duking': 8411,\n",
              " 'Thai': 4933,\n",
              " 'flagon': 8637,\n",
              " 'Rocks': 4891,\n",
              " 'Popsicle': 4883,\n",
              " 'Ballerinas': 6324,\n",
              " 'Pokemon': 4882,\n",
              " 'Performers': 4879,\n",
              " 'wrinkled': 10816,\n",
              " 'solitude': 10227,\n",
              " 'stock': 6011,\n",
              " 'Pabst': 4873,\n",
              " 'O': 4864,\n",
              " 'Nurses': 4863,\n",
              " 'based': 5045,\n",
              " 'actions': 4968,\n",
              " 'Dave': 6529,\n",
              " 'agricultural': 7508,\n",
              " 'Most': 4852,\n",
              " 'Michael': 4848,\n",
              " 'John': 2009,\n",
              " 'burly': 7859,\n",
              " 'Crouching': 4776,\n",
              " 'Los': 4841,\n",
              " 'butchered': 7873,\n",
              " 'Iowa': 4817,\n",
              " 'shrimp': 4570,\n",
              " 'Holding': 4812,\n",
              " 'Heineken': 4810,\n",
              " 'edibles': 8442,\n",
              " 'Groucho': 4808,\n",
              " 'bar': 385,\n",
              " 'torso': 10519,\n",
              " 'forklift': 4257,\n",
              " 'Free': 4800,\n",
              " 'Candy': 6416,\n",
              " 'Farmer': 4793,\n",
              " 'river': 317,\n",
              " 'labels': 9149,\n",
              " 'twirling': 3890,\n",
              " 'Evening': 4790,\n",
              " 'vests': 481,\n",
              " 'Employees': 4787,\n",
              " 'Deli': 4782,\n",
              " 'casino': 2524,\n",
              " 'divider': 8355,\n",
              " 'Business': 4760,\n",
              " 'ventilation': 10666,\n",
              " 'container': 1386,\n",
              " 'Jockeys': 4824,\n",
              " 'pruning': 4495,\n",
              " 'Bridesmaids': 4758,\n",
              " 'unpacking': 3894,\n",
              " 'Blurry': 4756,\n",
              " 'Billy': 6351,\n",
              " 'dozens': 8386,\n",
              " 'Bird': 4754,\n",
              " 'Beach': 4752,\n",
              " 'ShoeGasm': 7220,\n",
              " 'Baltimore': 4750,\n",
              " 'Attractive': 4748,\n",
              " 'Angeles': 4743,\n",
              " 'Britain': 6380,\n",
              " 'Am': 4742,\n",
              " 'debris': 1725,\n",
              " 'bunches': 7852,\n",
              " 'After': 4738,\n",
              " '80': 4736,\n",
              " '63': 4735,\n",
              " 'Snow': 4910,\n",
              " '14': 4731,\n",
              " 'midst': 2390,\n",
              " 'album': 4979,\n",
              " 'zombies': 4726,\n",
              " 'years': 4722,\n",
              " 'mannequins': 4374,\n",
              " 'instructions': 5521,\n",
              " 'woodworking': 4717,\n",
              " 'lock': 4363,\n",
              " 'fairgrounds': 8563,\n",
              " 'winded': 4716,\n",
              " 'darts': 4165,\n",
              " 'keg': 9114,\n",
              " 'walker': 4706,\n",
              " 'possessions': 9696,\n",
              " 'showcase': 10107,\n",
              " 'waking': 4705,\n",
              " 'Overweight': 7008,\n",
              " 'violins': 4701,\n",
              " 'freestyle': 5383,\n",
              " 'vacuums': 4693,\n",
              " 'Barbecue': 6326,\n",
              " 'tucks': 10580,\n",
              " 'Green': 2719,\n",
              " 'soothe': 10236,\n",
              " 'twirl': 4681,\n",
              " 'footrests': 8695,\n",
              " 'veil': 4695,\n",
              " 'turbans': 4674,\n",
              " 'trough': 4670,\n",
              " 'forward': 1574,\n",
              " 'Fairway': 6612,\n",
              " 'trouble': 4669,\n",
              " 'trots': 4668,\n",
              " 'tricycles': 4665,\n",
              " 'Eleven': 4786,\n",
              " 'topped': 4657,\n",
              " 'greens': 8833,\n",
              " 'toilets': 4655,\n",
              " 'backdropped': 7640,\n",
              " 'Memorial': 6923,\n",
              " 'thread': 4650,\n",
              " 'tethered': 4648,\n",
              " 'Wii': 4024,\n",
              " 'taped': 6055,\n",
              " 'testing': 4647,\n",
              " 'nail': 2396,\n",
              " 'dead': 1564,\n",
              " 'tambourine': 4637,\n",
              " 'takeout': 4635,\n",
              " 'jog': 3193,\n",
              " 'picker': 3698,\n",
              " 'Friends': 3385,\n",
              " 'streetlights': 4620,\n",
              " 'straining': 4617,\n",
              " 'Costco': 6496,\n",
              " 'downpour': 8382,\n",
              " 'Culture': 6508,\n",
              " 'Central': 4767,\n",
              " 'stained': 4610,\n",
              " 'chopped': 5162,\n",
              " 'b': 5027,\n",
              " 'UNICEF': 7359,\n",
              " 'Forever': 4799,\n",
              " 'daisies': 8239,\n",
              " 'sprinkled': 4604,\n",
              " 'spreading': 4602,\n",
              " 'tar': 10446,\n",
              " 'Event': 6601,\n",
              " 'spits': 4600,\n",
              " '11:27': 6200,\n",
              " 'speakers': 4595,\n",
              " 'cheerfully': 7970,\n",
              " 'sock': 4586,\n",
              " 'citizens': 3093,\n",
              " 'smirking': 4583,\n",
              " 'slowly': 4582,\n",
              " 'sleigh': 4581,\n",
              " 'declares': 8267,\n",
              " 'handicapped': 5448,\n",
              " 'shielding': 4569,\n",
              " 'tearing': 10454,\n",
              " 'poor': 1954,\n",
              " 'session': 4560,\n",
              " 'seas': 5888,\n",
              " 'sees': 4556,\n",
              " 'dive': 2189,\n",
              " 'blooming': 5072,\n",
              " 'screams': 4552,\n",
              " 'saxophones': 4549,\n",
              " 'goggles': 532,\n",
              " 'save': 4548,\n",
              " 'Maintenance': 4845,\n",
              " 'eyes': 553,\n",
              " 'die': 5273,\n",
              " 'sat': 4545,\n",
              " 'gaze': 2062,\n",
              " 'filing': 8620,\n",
              " 'edge': 496,\n",
              " 'rowers': 4538,\n",
              " 'route': 4537,\n",
              " 'rooster': 4536,\n",
              " 'reviewing': 4528,\n",
              " 'defending': 5259,\n",
              " 'mustaches': 9398,\n",
              " 'polishes': 9681,\n",
              " 'responding': 4525,\n",
              " 'rehearsing': 4517,\n",
              " 'Former': 6643,\n",
              " 'referees': 4515,\n",
              " 'recently': 4511,\n",
              " 'real': 4510,\n",
              " 'blocking': 2757,\n",
              " 'Rider': 4889,\n",
              " 'rakes': 4507,\n",
              " 'pump': 4497,\n",
              " 'orchard': 9477,\n",
              " 'pulley': 4496,\n",
              " 'palace': 5712,\n",
              " 'invisible': 9073,\n",
              " 'proudly': 4493,\n",
              " 'streaks': 4618,\n",
              " 'stationed': 10312,\n",
              " 'atop': 812,\n",
              " 'weather': 1999,\n",
              " 'western': 6164,\n",
              " 'trio': 4666,\n",
              " 'pregnant': 4479,\n",
              " 'prayer': 4478,\n",
              " 'jar': 3614,\n",
              " 'approximately': 4043,\n",
              " '60s': 6236,\n",
              " 'positions': 4474,\n",
              " 'portraits': 4473,\n",
              " 'bubble': 1174,\n",
              " 'ponytails': 4469,\n",
              " 'speech': 1322,\n",
              " 'windsurfs': 10778,\n",
              " 'ponchos': 4467,\n",
              " 'pointy': 4464,\n",
              " 'occupy': 9455,\n",
              " 'pleasant': 4461,\n",
              " 'Caucasians': 6430,\n",
              " 'flushed': 8674,\n",
              " 'skiff': 10150,\n",
              " 'pitched': 4458,\n",
              " 'pierced': 4456,\n",
              " 'per': 4454,\n",
              " 'somersault': 4590,\n",
              " 'bucks': 5106,\n",
              " 'charted': 7964,\n",
              " 'cramped': 5233,\n",
              " 'paying': 4451,\n",
              " 'zoom': 10835,\n",
              " 'pastor': 4442,\n",
              " 'Incredible': 6767,\n",
              " 'parlor': 4438,\n",
              " 'parka': 4437,\n",
              " 'pursued': 4499,\n",
              " 'camper': 3471,\n",
              " 'ethnicity': 8504,\n",
              " 'pant': 4436,\n",
              " 'paintball': 4431,\n",
              " 'gallopsing': 8748,\n",
              " 'pace': 4428,\n",
              " 'outfielder': 4423,\n",
              " 'wrists': 6187,\n",
              " 'trade': 6093,\n",
              " 'Whole': 7429,\n",
              " 'outcropping': 4422,\n",
              " 'text': 3329,\n",
              " 'upright': 3348,\n",
              " 'Gardening': 6661,\n",
              " 'horseshoes': 8951,\n",
              " 'observed': 4414,\n",
              " 'nursing': 4413,\n",
              " 'numbered': 4412,\n",
              " 'Elder': 3958,\n",
              " 'notice': 4410,\n",
              " 'glittery': 5412,\n",
              " 'exuberantly': 8548,\n",
              " 'nibbling': 4407,\n",
              " 'natural': 4403,\n",
              " 'university': 10623,\n",
              " 'huts': 4311,\n",
              " 'affected': 7494,\n",
              " 'moose': 4395,\n",
              " 'monks': 4393,\n",
              " 'informally': 5516,\n",
              " 'mock': 4392,\n",
              " 'mixed': 4390,\n",
              " 'illuminated': 2590,\n",
              " 'fountains': 2361,\n",
              " 'mirrored': 4389,\n",
              " 'shoots': 3785,\n",
              " 'miniskirt': 4388,\n",
              " 'attacking': 5018,\n",
              " 'Its': 6783,\n",
              " 'marina': 4376,\n",
              " 'log': 976,\n",
              " 'pouting': 4476,\n",
              " 'machete': 4368,\n",
              " 'lollipop': 4364,\n",
              " 'llama': 4362,\n",
              " 'furred': 8742,\n",
              " 'limo': 4358,\n",
              " 'tongs': 3335,\n",
              " 'ignores': 8997,\n",
              " 'Messi': 6925,\n",
              " 'let': 4354,\n",
              " 'leafy': 4350,\n",
              " 'latex': 4345,\n",
              " 'turkeys': 6116,\n",
              " 'pep': 9596,\n",
              " 'outstreached': 4424,\n",
              " 'lassoing': 4344,\n",
              " 'knives': 4340,\n",
              " 'clap': 2780,\n",
              " 'kneel': 4337,\n",
              " 'jumping': 97,\n",
              " 'keyboards': 4332,\n",
              " 'wheelchairs': 2977,\n",
              " 'key': 4331,\n",
              " 'kettle': 4330,\n",
              " 'kart': 4329,\n",
              " 'spice': 10263,\n",
              " 'Bieber': 6347,\n",
              " 'organic': 9479,\n",
              " 'rustle': 9974,\n",
              " 'index': 4312,\n",
              " 'shamrocks': 10067,\n",
              " 'sticking': 1274,\n",
              " 'huddling': 4309,\n",
              " 'Stanford': 7258,\n",
              " 'housing': 4308,\n",
              " 'radio': 2903,\n",
              " 'holing': 4305,\n",
              " 'agility': 4035,\n",
              " 'heartbeat': 4300,\n",
              " 'healthcare': 4299,\n",
              " 'Shorts': 4905,\n",
              " 'headgear': 4298,\n",
              " 'robes': 1024,\n",
              " 'kid': 362,\n",
              " 'Walkers': 4951,\n",
              " 'happening': 4295,\n",
              " 'growling': 5434,\n",
              " 'hamburgers': 4290,\n",
              " 'gypsy': 4286,\n",
              " \"'ll\": 6193,\n",
              " 'grid': 4279,\n",
              " 'demonstrating': 3520,\n",
              " 'greet': 4278,\n",
              " 'Average': 6314,\n",
              " 'avrovulcan.com': 7633,\n",
              " 'graphic': 4277,\n",
              " 'gifts': 4270,\n",
              " 'suv': 10396,\n",
              " 'peeking': 2236,\n",
              " 'frosting': 4263,\n",
              " 'older': 123,\n",
              " 'freeway': 4261,\n",
              " 'toast': 3877,\n",
              " 'vigorously': 4698,\n",
              " 'somewhat': 10234,\n",
              " 'fitness': 4246,\n",
              " 'fists': 4245,\n",
              " 'films': 4240,\n",
              " 'thick': 2682,\n",
              " 'toenails': 6085,\n",
              " 'footbridge': 3572,\n",
              " 'video': 803,\n",
              " 'faced': 4231,\n",
              " 'dapple': 8249,\n",
              " 'exposing': 4227,\n",
              " 'Ribbon': 4887,\n",
              " 'explosion': 4226,\n",
              " 'expensive': 4223,\n",
              " 'equipped': 4219,\n",
              " 'enthusiasm': 4217,\n",
              " 'polished': 9680,\n",
              " 'smokey': 10195,\n",
              " 'entertainment': 4215,\n",
              " 'entertaining': 4214,\n",
              " 'archaeologists': 7575,\n",
              " 'staff': 2439,\n",
              " 'enter': 4211,\n",
              " 'lift': 1052,\n",
              " 'Motorcycle': 4853,\n",
              " 'government': 4273,\n",
              " 'asians': 5008,\n",
              " 'boulders': 3450,\n",
              " 'dunks': 4195,\n",
              " 'menus': 4384,\n",
              " 'dugout': 4193,\n",
              " 'goggle': 8803,\n",
              " 'slamming': 5944,\n",
              " 'dozen': 4185,\n",
              " 'sequoia': 10055,\n",
              " 'resembles': 9896,\n",
              " 'partner': 4440,\n",
              " 'monitors': 2611,\n",
              " 'gum': 3170,\n",
              " 'propane': 4489,\n",
              " 'decals': 4167,\n",
              " 'loading': 1667,\n",
              " 'make': 513,\n",
              " 'darkness': 4164,\n",
              " 'patronizing': 9566,\n",
              " 'cycle': 4160,\n",
              " 'mat': 934,\n",
              " 'curtain': 4157,\n",
              " 'pajamas': 1149,\n",
              " 'peaceful': 4452,\n",
              " 'bracelets': 7796,\n",
              " 'roped': 9953,\n",
              " 'trident': 10561,\n",
              " 'Chung': 6454,\n",
              " 'craftsman': 4147,\n",
              " 'name': 1527,\n",
              " 'mooch': 9354,\n",
              " 'cracks': 4146,\n",
              " 'align': 4981,\n",
              " 'ceramic': 4119,\n",
              " 'task': 2273,\n",
              " 'countertop': 4143,\n",
              " 'cords': 4140,\n",
              " 'finale': 8622,\n",
              " 'cord': 4139,\n",
              " 'contains': 4137,\n",
              " 'collected': 4132,\n",
              " 'dig': 3129,\n",
              " 'lamp': 1581,\n",
              " 'john': 9090,\n",
              " 'Earth': 4785,\n",
              " 'surly': 10392,\n",
              " 'zombie': 4725,\n",
              " 'pages': 4430,\n",
              " 'cobbled': 4130,\n",
              " 'reverse': 9917,\n",
              " 'sauna': 4547,\n",
              " 'maneuver': 4370,\n",
              " 'visual': 10695,\n",
              " 'clerk': 4129,\n",
              " 'Performing': 7044,\n",
              " 'better': 4083,\n",
              " 'master': 4379,\n",
              " 'clams': 4126,\n",
              " 'flare': 8643,\n",
              " 'chart': 4123,\n",
              " 'Park': 3401,\n",
              " 'captures': 4118,\n",
              " 'ten': 6065,\n",
              " 'captured': 4117,\n",
              " 'captain': 4116,\n",
              " 'pride': 3259,\n",
              " 'diverse': 4181,\n",
              " 'Foods': 4798,\n",
              " 'canister': 4113,\n",
              " 'canes': 4112,\n",
              " 'cameramen': 4110,\n",
              " 'cabinet': 4106,\n",
              " 'oppsing': 9474,\n",
              " 'butchering': 4103,\n",
              " 'uniforms': 345,\n",
              " 'bumper': 4102,\n",
              " 'recline': 9833,\n",
              " 'briskly': 4100,\n",
              " 'vegetated': 10663,\n",
              " 'cop': 2039,\n",
              " 'bordered': 4090,\n",
              " 'boa': 4088,\n",
              " 'blurry': 4087,\n",
              " 'blossoming': 4086,\n",
              " 'tailcoat': 10431,\n",
              " 'blacktop': 4084,\n",
              " 'ends': 4208,\n",
              " 'shoot': 1368,\n",
              " 'bears': 4077,\n",
              " 'participating': 1225,\n",
              " 'serious': 5903,\n",
              " 'beagle': 4074,\n",
              " 'bay': 4072,\n",
              " 'unfamiliar': 10613,\n",
              " 'bit': 2756,\n",
              " 'whisking': 6166,\n",
              " 'bats': 4070,\n",
              " 'scythe': 5885,\n",
              " 'baggage': 4061,\n",
              " 'memorial': 3648,\n",
              " 'way': 728,\n",
              " 'awning': 4058,\n",
              " 'upcoming': 4689,\n",
              " 'bushy': 3071,\n",
              " 'awaits': 4056,\n",
              " 'Bread': 6373,\n",
              " 'cross': 484,\n",
              " 'attend': 4053,\n",
              " 'attaches': 4052,\n",
              " 'covers': 1899,\n",
              " 'Cheesecake': 6438,\n",
              " 'astronaut': 4051,\n",
              " 'cow': 950,\n",
              " 'Year': 4961,\n",
              " 'assembly': 4049,\n",
              " 'flooded': 4252,\n",
              " 'headbutting': 8895,\n",
              " 'amazing': 4038,\n",
              " 'comb': 4134,\n",
              " 'admires': 4032,\n",
              " 'rappelling': 4508,\n",
              " 'boxes': 968,\n",
              " 'Starting': 7260,\n",
              " 'ankle': 4994,\n",
              " 'digger': 4175,\n",
              " 'addresses': 4029,\n",
              " 'pulled': 918,\n",
              " 'accompanies': 4027,\n",
              " 'forming': 3160,\n",
              " 'consult': 8118,\n",
              " 'Tye': 4022,\n",
              " 'suit': 200,\n",
              " 'Peeps': 7037,\n",
              " 'offering': 3229,\n",
              " 'overpass': 4427,\n",
              " 'Sports': 4014,\n",
              " 'Skier': 4009,\n",
              " 'spoonful': 10277,\n",
              " 'redwood': 9841,\n",
              " 'Birthday': 4755,\n",
              " 'Scottish': 4007,\n",
              " 'struggle': 6020,\n",
              " 'Run': 4005,\n",
              " 'Player': 4002,\n",
              " 'Overhead': 3997,\n",
              " 'Latino': 3984,\n",
              " 'Korean': 3981,\n",
              " 'bananas': 2506,\n",
              " 'bikini': 605,\n",
              " 'poultry': 5766,\n",
              " 'Italian': 3978,\n",
              " 'Individuals': 3977,\n",
              " 'Homeless': 3976,\n",
              " 'butter': 4105,\n",
              " 'Hikers': 3974,\n",
              " 'paraphernalia': 5717,\n",
              " 'Hard': 3973,\n",
              " 'gymnast': 994,\n",
              " 'gates': 5405,\n",
              " 'gliders': 8789,\n",
              " 'Dozens': 3955,\n",
              " 'considerably': 8110,\n",
              " 'Dad': 3954,\n",
              " 'geyser': 8771,\n",
              " 'scottish': 10009,\n",
              " 'grimacing': 4280,\n",
              " 'dinosaurs': 8330,\n",
              " 'Colorful': 3950,\n",
              " 'Bull': 3947,\n",
              " 'swinger': 10412,\n",
              " 'ping': 3249,\n",
              " 'White': 1169,\n",
              " 'those': 2963,\n",
              " 'Brazil': 3946,\n",
              " 'quirky': 9794,\n",
              " 'Berlin': 3945,\n",
              " 'multitasking': 5666,\n",
              " 'All': 3939,\n",
              " 'Africa': 3938,\n",
              " 'hurting': 8979,\n",
              " 'A&amp;M': 3937,\n",
              " 'NY': 2727,\n",
              " 'Takes': 7301,\n",
              " 'Ocean': 3996,\n",
              " '3rd': 3936,\n",
              " '12': 3933,\n",
              " 'lane': 1353,\n",
              " 'visor': 2699,\n",
              " 'wraps': 3927,\n",
              " 'take': 399,\n",
              " 'Wader': 7406,\n",
              " 'desert': 853,\n",
              " 'other': 75,\n",
              " 'ascends': 5007,\n",
              " 'senior': 2928,\n",
              " 'computer': 435,\n",
              " 'seductively': 10045,\n",
              " 'Scuba': 4899,\n",
              " 'gets': 656,\n",
              " 'wigs': 3921,\n",
              " 'bridesmaids': 2766,\n",
              " 'wetsuits': 3917,\n",
              " 'patron': 4447,\n",
              " 'Cyclone': 4777,\n",
              " 'weave': 3913,\n",
              " 'series': 2929,\n",
              " 'washed': 3909,\n",
              " 'pets': 4455,\n",
              " 'warning': 3908,\n",
              " 'Giant': 4803,\n",
              " 'rifles': 5840,\n",
              " 'plains': 9652,\n",
              " 'walkers': 3906,\n",
              " 'reclined': 9834,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_transform['en'].get_itos() # list of tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-rWlZrpDdN_",
        "outputId": "a0571fb5-5e6f-41e8-b540-ebb2c498816f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>',\n",
              " '<pad>',\n",
              " '<bos>',\n",
              " '<eos>',\n",
              " 'a',\n",
              " '.',\n",
              " 'A',\n",
              " 'in',\n",
              " 'the',\n",
              " 'on',\n",
              " 'is',\n",
              " 'and',\n",
              " 'man',\n",
              " 'of',\n",
              " 'with',\n",
              " ',',\n",
              " 'woman',\n",
              " 'are',\n",
              " 'to',\n",
              " 'Two',\n",
              " 'at',\n",
              " 'wearing',\n",
              " 'people',\n",
              " 'shirt',\n",
              " 'white',\n",
              " 'young',\n",
              " 'black',\n",
              " 'his',\n",
              " 'an',\n",
              " 'while',\n",
              " 'blue',\n",
              " 'red',\n",
              " 'sitting',\n",
              " 'girl',\n",
              " 'dog',\n",
              " 'boy',\n",
              " 'men',\n",
              " 'standing',\n",
              " 'playing',\n",
              " 'group',\n",
              " 'street',\n",
              " 'down',\n",
              " 'walking',\n",
              " '-',\n",
              " 'front',\n",
              " 'her',\n",
              " 'holding',\n",
              " 'water',\n",
              " 'by',\n",
              " 'The',\n",
              " 'up',\n",
              " 'green',\n",
              " 'women',\n",
              " 'An',\n",
              " 'one',\n",
              " 'for',\n",
              " 'looking',\n",
              " 'outside',\n",
              " 'child',\n",
              " 'Three',\n",
              " 'as',\n",
              " 'little',\n",
              " 'large',\n",
              " 'through',\n",
              " 'yellow',\n",
              " 'brown',\n",
              " 'two',\n",
              " 'from',\n",
              " 'hat',\n",
              " 'ball',\n",
              " 'their',\n",
              " 'into',\n",
              " 'person',\n",
              " 'children',\n",
              " 'next',\n",
              " 'other',\n",
              " 'dressed',\n",
              " 'small',\n",
              " 'out',\n",
              " 'over',\n",
              " 'building',\n",
              " 'riding',\n",
              " 'running',\n",
              " 'People',\n",
              " 'near',\n",
              " 'jacket',\n",
              " 'another',\n",
              " 'around',\n",
              " 'some',\n",
              " 'sidewalk',\n",
              " 'field',\n",
              " 'orange',\n",
              " 'beach',\n",
              " 'crowd',\n",
              " 'stands',\n",
              " 'pink',\n",
              " 'sits',\n",
              " 'jumping',\n",
              " 'behind',\n",
              " 'table',\n",
              " 'snow',\n",
              " 'grass',\n",
              " 'hair',\n",
              " 'background',\n",
              " 'stand',\n",
              " 'bike',\n",
              " \"'s\",\n",
              " 'air',\n",
              " 'city',\n",
              " 'player',\n",
              " 'girls',\n",
              " 'Man',\n",
              " 'looks',\n",
              " 'top',\n",
              " 'wall',\n",
              " 'off',\n",
              " 'that',\n",
              " 'dogs',\n",
              " 'camera',\n",
              " 'dress',\n",
              " 'park',\n",
              " 'talking',\n",
              " 'something',\n",
              " 'older',\n",
              " 'along',\n",
              " 'walks',\n",
              " 'guitar',\n",
              " 'play',\n",
              " 'lady',\n",
              " 'soccer',\n",
              " 'together',\n",
              " 'working',\n",
              " 'blond',\n",
              " 'boys',\n",
              " 'food',\n",
              " 'gray',\n",
              " 'smiling',\n",
              " 'game',\n",
              " 'has',\n",
              " 'picture',\n",
              " 'plays',\n",
              " 'Asian',\n",
              " 'hand',\n",
              " 'car',\n",
              " 'holds',\n",
              " 'Four',\n",
              " 'him',\n",
              " 'road',\n",
              " 'bench',\n",
              " 'it',\n",
              " 'glasses',\n",
              " 'pants',\n",
              " 'stage',\n",
              " 'shorts',\n",
              " 'sit',\n",
              " 'carrying',\n",
              " 'walk',\n",
              " 'baby',\n",
              " 'couple',\n",
              " 'them',\n",
              " 'bicycle',\n",
              " 'face',\n",
              " 'side',\n",
              " 'tree',\n",
              " '\"',\n",
              " 'Several',\n",
              " 'old',\n",
              " 'pool',\n",
              " 'taking',\n",
              " 'rock',\n",
              " 'each',\n",
              " 'long',\n",
              " 'race',\n",
              " 'doing',\n",
              " 'across',\n",
              " 'watching',\n",
              " 'head',\n",
              " 'jeans',\n",
              " 'area',\n",
              " 'dirt',\n",
              " 'male',\n",
              " 'middle',\n",
              " 'dark',\n",
              " 'jumps',\n",
              " 'boat',\n",
              " 'hands',\n",
              " 'back',\n",
              " 'ground',\n",
              " 'performing',\n",
              " 'room',\n",
              " 'day',\n",
              " 'who',\n",
              " 'eating',\n",
              " 'female',\n",
              " 'being',\n",
              " 'baseball',\n",
              " 'guy',\n",
              " 'coat',\n",
              " 'striped',\n",
              " 'using',\n",
              " 'suit',\n",
              " 'under',\n",
              " 'football',\n",
              " 'horse',\n",
              " 'watch',\n",
              " 'mouth',\n",
              " 'purple',\n",
              " 'sign',\n",
              " 'store',\n",
              " 'haired',\n",
              " 'he',\n",
              " 'sand',\n",
              " 'band',\n",
              " 'runs',\n",
              " 'look',\n",
              " 'tennis',\n",
              " 'Young',\n",
              " 'reading',\n",
              " 'sunglasses',\n",
              " 'clothing',\n",
              " 'microphone',\n",
              " 'players',\n",
              " 'three',\n",
              " 'There',\n",
              " 'covered',\n",
              " 'mountain',\n",
              " 't',\n",
              " 'toy',\n",
              " 'its',\n",
              " 'ocean',\n",
              " 'watches',\n",
              " 'basketball',\n",
              " 'climbing',\n",
              " 'during',\n",
              " 'uniform',\n",
              " 'kids',\n",
              " 'past',\n",
              " 'helmet',\n",
              " 'restaurant',\n",
              " 'against',\n",
              " 'train',\n",
              " 'dancing',\n",
              " 'window',\n",
              " 'rides',\n",
              " 'team',\n",
              " 'elderly',\n",
              " 'shirts',\n",
              " 'chair',\n",
              " 'work',\n",
              " 'be',\n",
              " 'One',\n",
              " 'posing',\n",
              " 'trees',\n",
              " 'wooden',\n",
              " 'about',\n",
              " 'having',\n",
              " 'outdoor',\n",
              " 'they',\n",
              " 'waiting',\n",
              " 'swimming',\n",
              " 'getting',\n",
              " 'all',\n",
              " 'floor',\n",
              " 'or',\n",
              " 'construction',\n",
              " 'trying',\n",
              " 'workers',\n",
              " 'skateboard',\n",
              " 'very',\n",
              " 'bag',\n",
              " 'busy',\n",
              " 'colorful',\n",
              " 'ice',\n",
              " 'singing',\n",
              " 'fence',\n",
              " 'Woman',\n",
              " 'high',\n",
              " 'jump',\n",
              " 'This',\n",
              " 'cart',\n",
              " 'line',\n",
              " 'laying',\n",
              " 'truck',\n",
              " 'hill',\n",
              " 'Men',\n",
              " 'book',\n",
              " 'bright',\n",
              " 'hats',\n",
              " 'ride',\n",
              " 'cap',\n",
              " 'inside',\n",
              " 'kitchen',\n",
              " 'market',\n",
              " 'others',\n",
              " 'tan',\n",
              " 'cellphone',\n",
              " 'grassy',\n",
              " 'path',\n",
              " 'making',\n",
              " 'bus',\n",
              " 'clothes',\n",
              " 'brick',\n",
              " 'takes',\n",
              " 'umbrella',\n",
              " 'big',\n",
              " 'full',\n",
              " 'light',\n",
              " 'motorcycle',\n",
              " 'outfit',\n",
              " 'towards',\n",
              " 'track',\n",
              " 'body',\n",
              " 'night',\n",
              " 'enjoying',\n",
              " 'metal',\n",
              " 'swing',\n",
              " 'colored',\n",
              " 'river',\n",
              " 'open',\n",
              " 'paper',\n",
              " 'ready',\n",
              " 'tank',\n",
              " 'piece',\n",
              " 'Five',\n",
              " 'sweater',\n",
              " 'lake',\n",
              " 'she',\n",
              " 'shop',\n",
              " 'trick',\n",
              " 'above',\n",
              " 'painting',\n",
              " 'several',\n",
              " 'going',\n",
              " 'run',\n",
              " 'dance',\n",
              " 'hard',\n",
              " 'many',\n",
              " 'snowy',\n",
              " 'shopping',\n",
              " 'stone',\n",
              " 'wave',\n",
              " 'music',\n",
              " 'onto',\n",
              " 'stick',\n",
              " 'surrounded',\n",
              " 'uniforms',\n",
              " 'vest',\n",
              " 'like',\n",
              " 'worker',\n",
              " 'backpack',\n",
              " 'crowded',\n",
              " 'smiles',\n",
              " 'beside',\n",
              " 'board',\n",
              " 'outdoors',\n",
              " 'photo',\n",
              " 'adults',\n",
              " 'pole',\n",
              " 'drinking',\n",
              " 'gear',\n",
              " 'phone',\n",
              " 'house',\n",
              " 'kid',\n",
              " 'gathered',\n",
              " 'event',\n",
              " 'hanging',\n",
              " 'set',\n",
              " 'bridge',\n",
              " 'catch',\n",
              " 'subway',\n",
              " 'African',\n",
              " 'arms',\n",
              " 'away',\n",
              " 'family',\n",
              " 'flowers',\n",
              " 'preparing',\n",
              " 'costume',\n",
              " 'hockey',\n",
              " 'leaning',\n",
              " 'object',\n",
              " 'toddler',\n",
              " 'Many',\n",
              " 'fishing',\n",
              " 'sleeping',\n",
              " 'steps',\n",
              " 'bar',\n",
              " 'does',\n",
              " 'fire',\n",
              " 'guys',\n",
              " 'Children',\n",
              " 'after',\n",
              " 'fountain',\n",
              " 'lot',\n",
              " 'machine',\n",
              " 'plaid',\n",
              " 'rope',\n",
              " 'short',\n",
              " 'beautiful',\n",
              " 'American',\n",
              " 'take',\n",
              " 'adult',\n",
              " 'asian',\n",
              " 'graffiti',\n",
              " 'stairs',\n",
              " 'police',\n",
              " 'shoes',\n",
              " 'arm',\n",
              " 'selling',\n",
              " 'shirtless',\n",
              " 'forest',\n",
              " 'sunny',\n",
              " 'rocks',\n",
              " 'setting',\n",
              " 'four',\n",
              " 'pose',\n",
              " 'both',\n",
              " 'chairs',\n",
              " 'corner',\n",
              " 'putting',\n",
              " 'racing',\n",
              " 'glass',\n",
              " 'pushing',\n",
              " 'tall',\n",
              " 'throwing',\n",
              " 'between',\n",
              " 'drink',\n",
              " 'have',\n",
              " 'parade',\n",
              " 'slide',\n",
              " 'volleyball',\n",
              " '2',\n",
              " 'Some',\n",
              " 'ladies',\n",
              " 'laughing',\n",
              " 'public',\n",
              " 'computer',\n",
              " 'equipment',\n",
              " 'instruments',\n",
              " 'someone',\n",
              " 'couch',\n",
              " 'wood',\n",
              " 'flag',\n",
              " 'pictures',\n",
              " 'plastic',\n",
              " 'ramp',\n",
              " 'sun',\n",
              " 'aged',\n",
              " 'concrete',\n",
              " 'party',\n",
              " 'playground',\n",
              " 'poses',\n",
              " 'sweatshirt',\n",
              " 'trail',\n",
              " 'which',\n",
              " 'woods',\n",
              " 'beard',\n",
              " 'fish',\n",
              " 'statue',\n",
              " 'view',\n",
              " 'dock',\n",
              " 'midair',\n",
              " 'winter',\n",
              " 'yard',\n",
              " 'bikes',\n",
              " 'cowboy',\n",
              " 'number',\n",
              " 'skirt',\n",
              " 'distance',\n",
              " 'attire',\n",
              " 'just',\n",
              " 'reads',\n",
              " 'seated',\n",
              " 'toward',\n",
              " 'get',\n",
              " 'left',\n",
              " 'what',\n",
              " 'works',\n",
              " 'beer',\n",
              " 'cooking',\n",
              " 'cutting',\n",
              " 'sky',\n",
              " 'vests',\n",
              " 'bags',\n",
              " 'buildings',\n",
              " 'cross',\n",
              " 'filled',\n",
              " 'lined',\n",
              " 'pulling',\n",
              " 'Little',\n",
              " 'cream',\n",
              " 'rider',\n",
              " 'where',\n",
              " 'appears',\n",
              " 'bed',\n",
              " 'cliff',\n",
              " 'crossing',\n",
              " 'edge',\n",
              " 'instrument',\n",
              " 'mountains',\n",
              " 'showing',\n",
              " 'tent',\n",
              " 'court',\n",
              " 'Women',\n",
              " 'jersey',\n",
              " 'nearby',\n",
              " 'performs',\n",
              " 'scarf',\n",
              " 'Frisbee',\n",
              " 'apron',\n",
              " 'carries',\n",
              " 'driving',\n",
              " 'few',\n",
              " 'horses',\n",
              " 'make',\n",
              " 'perform',\n",
              " 'right',\n",
              " 'school',\n",
              " 'station',\n",
              " 'art',\n",
              " 'bowling',\n",
              " 'friends',\n",
              " 'grill',\n",
              " 'leaves',\n",
              " 'shore',\n",
              " 'show',\n",
              " 'boots',\n",
              " 'cars',\n",
              " 'cigarette',\n",
              " 'cup',\n",
              " 'fruit',\n",
              " 'parked',\n",
              " 'structure',\n",
              " 'goggles',\n",
              " 'painted',\n",
              " 'smile',\n",
              " 'snowboarder',\n",
              " 'vendor',\n",
              " 'Person',\n",
              " 'bottle',\n",
              " 'door',\n",
              " 'dresses',\n",
              " 'drums',\n",
              " 'flower',\n",
              " 'flying',\n",
              " 'martial',\n",
              " 'net',\n",
              " 'skateboarder',\n",
              " 'smoking',\n",
              " 'talks',\n",
              " 'vehicle',\n",
              " 'bathing',\n",
              " 'coffee',\n",
              " 'concert',\n",
              " 'eyes',\n",
              " 'hit',\n",
              " 'home',\n",
              " 'lying',\n",
              " 'rocky',\n",
              " 'shot',\n",
              " 'time',\n",
              " 'Group',\n",
              " 'arts',\n",
              " 'flags',\n",
              " 'jackets',\n",
              " 'kicking',\n",
              " 'mother',\n",
              " 'newspaper',\n",
              " 'paint',\n",
              " 'prepares',\n",
              " 'rain',\n",
              " 'safety',\n",
              " 'swinging',\n",
              " 'waves',\n",
              " 'younger',\n",
              " 'box',\n",
              " 'bucket',\n",
              " 'conversation',\n",
              " 'costumes',\n",
              " 'gather',\n",
              " 'gentleman',\n",
              " 'gloves',\n",
              " 'practicing',\n",
              " 'spectators',\n",
              " 'Boy',\n",
              " 'bearded',\n",
              " 'bunch',\n",
              " 'cleaning',\n",
              " 'competition',\n",
              " 'different',\n",
              " 'ladder',\n",
              " 'listening',\n",
              " 'no',\n",
              " 'parking',\n",
              " 'roof',\n",
              " 'this',\n",
              " 'uses',\n",
              " 'blanket',\n",
              " 'items',\n",
              " 'scene',\n",
              " 'skateboarding',\n",
              " 'staring',\n",
              " 'there',\n",
              " 'audience',\n",
              " 'balloon',\n",
              " 'bicycles',\n",
              " 'bikini',\n",
              " 'desk',\n",
              " 'empty',\n",
              " 'giving',\n",
              " 'lawn',\n",
              " 'meal',\n",
              " 'pile',\n",
              " 'railing',\n",
              " 'surfer',\n",
              " 'various',\n",
              " 'Someone',\n",
              " 'drinks',\n",
              " 'leaps',\n",
              " 'onlookers',\n",
              " 'rodeo',\n",
              " 'Girl',\n",
              " 'cake',\n",
              " 'display',\n",
              " 'gathering',\n",
              " 'go',\n",
              " 'hold',\n",
              " 'hot',\n",
              " 'pointing',\n",
              " 'sliding',\n",
              " 'vegetables',\n",
              " 'Indian',\n",
              " 'basket',\n",
              " 'bowl',\n",
              " 'bull',\n",
              " 'class',\n",
              " 'facing',\n",
              " 'feet',\n",
              " 'gold',\n",
              " 'streets',\n",
              " 'suits',\n",
              " 'wet',\n",
              " 'before',\n",
              " 'biker',\n",
              " 'cement',\n",
              " 'competing',\n",
              " 'flip',\n",
              " 'helmets',\n",
              " 'mask',\n",
              " 'platform',\n",
              " 'silver',\n",
              " 'speaking',\n",
              " 'sports',\n",
              " 'wedding',\n",
              " 'Six',\n",
              " 'classroom',\n",
              " 'coming',\n",
              " 'gets',\n",
              " 'huge',\n",
              " 'lit',\n",
              " 'match',\n",
              " 'stop',\n",
              " 'teams',\n",
              " 'tie',\n",
              " 'bird',\n",
              " 'climbs',\n",
              " 'purse',\n",
              " 'sings',\n",
              " 'students',\n",
              " 'surfboard',\n",
              " 'surfing',\n",
              " 'traditional',\n",
              " 'tries',\n",
              " 'wait',\n",
              " 'alley',\n",
              " 'animal',\n",
              " 'bride',\n",
              " 'can',\n",
              " 'chasing',\n",
              " 'counter',\n",
              " 'fighting',\n",
              " 'kissing',\n",
              " 'military',\n",
              " 'rail',\n",
              " 'screen',\n",
              " 'ski',\n",
              " 'break',\n",
              " 'same',\n",
              " 'skating',\n",
              " 'stroller',\n",
              " 'country',\n",
              " 'females',\n",
              " 'kneeling',\n",
              " 'lap',\n",
              " 'pass',\n",
              " 'shoulder',\n",
              " 'skier',\n",
              " 'sunset',\n",
              " 'throw',\n",
              " 'waits',\n",
              " 'walkway',\n",
              " 'writing',\n",
              " '3',\n",
              " 'attempting',\n",
              " 'runner',\n",
              " 'scooter',\n",
              " 'sort',\n",
              " 'talk',\n",
              " 'waving',\n",
              " 'marathon',\n",
              " 'outfits',\n",
              " 'place',\n",
              " 'seen',\n",
              " 'signs',\n",
              " 'violin',\n",
              " 'bald',\n",
              " 'blowing',\n",
              " 'bubbles',\n",
              " 'business',\n",
              " 'close',\n",
              " 'course',\n",
              " 'five',\n",
              " 'hole',\n",
              " 'mirror',\n",
              " 'officer',\n",
              " 'overlooking',\n",
              " 'says',\n",
              " 'son',\n",
              " 'tables',\n",
              " 'way',\n",
              " 'balloons',\n",
              " 'base',\n",
              " 'fixing',\n",
              " 'happy',\n",
              " 'leans',\n",
              " 'lights',\n",
              " 'urban',\n",
              " 'Construction',\n",
              " 'alone',\n",
              " 'artist',\n",
              " 'brightly',\n",
              " 'collar',\n",
              " 'faces',\n",
              " 'father',\n",
              " 'foreground',\n",
              " 'gym',\n",
              " 'helping',\n",
              " 'leather',\n",
              " 'leg',\n",
              " 'life',\n",
              " 'made',\n",
              " 'musicians',\n",
              " 'swim',\n",
              " 'umbrellas',\n",
              " 'asleep',\n",
              " 'clown',\n",
              " 'do',\n",
              " 'electric',\n",
              " 'enjoy',\n",
              " 'giant',\n",
              " 'headphones',\n",
              " 'legs',\n",
              " 'meat',\n",
              " 'plate',\n",
              " 'site',\n",
              " 'skate',\n",
              " 'among',\n",
              " 'diving',\n",
              " 'end',\n",
              " 'falling',\n",
              " 'golf',\n",
              " 'makes',\n",
              " 'mud',\n",
              " 'office',\n",
              " 'passing',\n",
              " 'sandals',\n",
              " 'stadium',\n",
              " 'sticks',\n",
              " 'swings',\n",
              " 'washing',\n",
              " 'wears',\n",
              " 'canoe',\n",
              " 'doorway',\n",
              " 'goal',\n",
              " 'heads',\n",
              " 'multicolored',\n",
              " 'musical',\n",
              " 'officers',\n",
              " 'roller',\n",
              " 'skiing',\n",
              " 'toys',\n",
              " 'well',\n",
              " 'accordion',\n",
              " 'barefoot',\n",
              " 'church',\n",
              " 'dirty',\n",
              " 'drawing',\n",
              " 'laptop',\n",
              " 'leash',\n",
              " 'photographer',\n",
              " 'picking',\n",
              " 'reaching',\n",
              " 'teenage',\n",
              " 'throws',\n",
              " 'video',\n",
              " 'In',\n",
              " 'below',\n",
              " 'digging',\n",
              " 'hiking',\n",
              " 'males',\n",
              " 'performance',\n",
              " 'shallow',\n",
              " 'traffic',\n",
              " 'atop',\n",
              " 'cat',\n",
              " 'catches',\n",
              " 'catching',\n",
              " 'foot',\n",
              " 'gives',\n",
              " 'hugging',\n",
              " 'microscope',\n",
              " 'new',\n",
              " 'passes',\n",
              " 'relaxing',\n",
              " 'row',\n",
              " 'shovel',\n",
              " 'tunnel',\n",
              " 'upside',\n",
              " 'van',\n",
              " 'wheel',\n",
              " 'Chinese',\n",
              " 'Christmas',\n",
              " 'balls',\n",
              " 'beige',\n",
              " 'brunette',\n",
              " 'climb',\n",
              " 'cut',\n",
              " 'dancers',\n",
              " 'deep',\n",
              " 'drum',\n",
              " 'fun',\n",
              " 'kick',\n",
              " 'leaping',\n",
              " 'prepare',\n",
              " 'shows',\n",
              " 'sleeps',\n",
              " 'stunt',\n",
              " 'sweeping',\n",
              " 'tattoo',\n",
              " 'cafe',\n",
              " 'chef',\n",
              " 'coats',\n",
              " 'conversing',\n",
              " 'daughter',\n",
              " 'desert',\n",
              " 'flies',\n",
              " 'garden',\n",
              " 'hoodie',\n",
              " 'hose',\n",
              " 'move',\n",
              " 'photograph',\n",
              " 'pond',\n",
              " 'resting',\n",
              " 'sculpture',\n",
              " 'singer',\n",
              " 'teeth',\n",
              " 'trunks',\n",
              " ';',\n",
              " 'bat',\n",
              " 'cold',\n",
              " 'friend',\n",
              " 'held',\n",
              " 'jogging',\n",
              " 'karate',\n",
              " 'pier',\n",
              " 'plants',\n",
              " 'points',\n",
              " 'sled',\n",
              " 'splashing',\n",
              " 'telescope',\n",
              " 'tire',\n",
              " 'town',\n",
              " 'underneath',\n",
              " 'wrestling',\n",
              " 'Black',\n",
              " 'Kids',\n",
              " 'block',\n",
              " 'cane',\n",
              " 'curly',\n",
              " 'eat',\n",
              " 'how',\n",
              " 'including',\n",
              " 'moving',\n",
              " 'project',\n",
              " 'shoulders',\n",
              " 'themselves',\n",
              " 'waters',\n",
              " 'without',\n",
              " 'Old',\n",
              " 'Small',\n",
              " 'Workers',\n",
              " 'bicyclist',\n",
              " 'carnival',\n",
              " 'circle',\n",
              " 'cloth',\n",
              " 'crosswalk',\n",
              " 'crying',\n",
              " 'cyclist',\n",
              " 'dinner',\n",
              " 'gun',\n",
              " 'hiker',\n",
              " 'hula',\n",
              " 'individuals',\n",
              " 'makeup',\n",
              " 'matching',\n",
              " 'mural',\n",
              " 'opposing',\n",
              " 'paved',\n",
              " 'produce',\n",
              " 'pulled',\n",
              " 'racket',\n",
              " 'shoe',\n",
              " 'straw',\n",
              " 'taken',\n",
              " 'trampoline',\n",
              " 'tricks',\n",
              " 'wooded',\n",
              " 'attempts',\n",
              " 'closed',\n",
              " 'dances',\n",
              " 'formal',\n",
              " 'infant',\n",
              " 'knee',\n",
              " 'lab',\n",
              " 'lone',\n",
              " 'mat',\n",
              " 'members',\n",
              " 'nose',\n",
              " 'performer',\n",
              " 'picnic',\n",
              " 'rolling',\n",
              " 'sewing',\n",
              " 'stuffed',\n",
              " 'surface',\n",
              " 'trash',\n",
              " \"'\",\n",
              " 'These',\n",
              " 'balcony',\n",
              " 'blouse',\n",
              " 'booth',\n",
              " 'center',\n",
              " 'cow',\n",
              " 'fight',\n",
              " 'goes',\n",
              " 'help',\n",
              " 'himself',\n",
              " 'lays',\n",
              " 'neck',\n",
              " 'opening',\n",
              " 'pushes',\n",
              " 'ring',\n",
              " 'round',\n",
              " 'slope',\n",
              " 'softball',\n",
              " 'square',\n",
              " 'third',\n",
              " 'wear',\n",
              " 'athlete',\n",
              " 'bent',\n",
              " 'boxes',\n",
              " 'button',\n",
              " 'chases',\n",
              " 'deck',\n",
              " 'device',\n",
              " 'hoop',\n",
              " 'indoor',\n",
              " 'kind',\n",
              " 'log',\n",
              " 'lunch',\n",
              " 'not',\n",
              " 'pulls',\n",
              " 'puts',\n",
              " 'sandy',\n",
              " 'skis',\n",
              " 'speaks',\n",
              " 'staircase',\n",
              " 'turn',\n",
              " 'Guy',\n",
              " 'books',\n",
              " 'covering',\n",
              " 'drives',\n",
              " 'enjoys',\n",
              " 'fallen',\n",
              " 'festival',\n",
              " 'grocery',\n",
              " 'gymnast',\n",
              " 'overalls',\n",
              " 'robe',\n",
              " 'shaking',\n",
              " 'swims',\n",
              " 'wetsuit',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "  vocab_transform[ln].set_default_index(UNK_IDX)"
      ],
      "metadata": {
        "id": "7snI6F4dETKh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer is a Seq2Seq model introduced in “Attention is all you need” paper for solving machine translation tasks. Below, we will create a Seq2Seq network that uses Transformer. The network consists of three parts. First part is the embedding layer. This layer converts tensor of input indices into corresponding tensor of input embeddings. These embedding are further augmented with positional encodings to provide position information of input tokens to the model. The second part is the actual Transformer model. Finally, the output of the Transformer model is passed through linear layer that gives unnormalized probabilities for each token in the target language."
      ],
      "metadata": {
        "id": "ZEpzQ05BEy1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math"
      ],
      "metadata": {
        "id": "biohyGD1EZ49"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "UNbZDx_mFZho"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXhS1n_9Ffww",
        "outputId": "29d87ac5-12c9-4e7f-dd1a-848cfe872283"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])"
      ],
      "metadata": {
        "id": "bP4ikd5eFsO1"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
      ],
      "metadata": {
        "id": "JLxBwYUsLaVb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        self.transformer = Transformer(d_model=emb_size,\n",
        "                                       nhead=nhead,\n",
        "                                       num_encoder_layers=num_encoder_layers,\n",
        "                                       num_decoder_layers=num_decoder_layers,\n",
        "                                       dim_feedforward=dim_feedforward,\n",
        "                                       dropout=dropout)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
        "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(outs)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer.encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer.decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)"
      ],
      "metadata": {
        "id": "ojuzaPrsMIZS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask"
      ],
      "metadata": {
        "id": "wqWjER_ePebA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ],
      "metadata": {
        "id": "buylRRaLR5yx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "EMB_SIZE = 512\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 128\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(DEVICE)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ],
      "metadata": {
        "id": "cELi_g7kSD6Q"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ],
      "metadata": {
        "id": "sHb3P8clTJeP"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def train_epoch(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in train_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(train_dataloader))\n",
        "\n",
        "\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(val_dataloader))"
      ],
      "metadata": {
        "id": "24Wzu36yT5Yf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from timeit import default_timer as timer\n",
        "import torch\n",
        "\n",
        "NUM_EPOCHS = 18\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train_epoch(transformer, optimizer)\n",
        "    end_time = timer()\n",
        "    val_loss = evaluate(transformer)\n",
        "    print(f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, Epoch time = {(end_time - start_time):.3f}s\")\n",
        "\n",
        "filename = f\"saved_model.pt\"\n",
        "torch.save(transformer.state_dict(), filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2iHlKzKVN85",
        "outputId": "44cdbc13-f820-4c2a-a8da-b6c3cfdf9b0a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train loss: 0.353, Val loss: 2.162, Epoch time = 46.399s\n",
            "Epoch: 2, Train loss: 0.328, Val loss: 2.185, Epoch time = 45.341s\n",
            "Epoch: 3, Train loss: 0.304, Val loss: 2.235, Epoch time = 46.431s\n",
            "Epoch: 4, Train loss: 0.285, Val loss: 2.254, Epoch time = 45.167s\n",
            "Epoch: 5, Train loss: 0.267, Val loss: 2.268, Epoch time = 46.409s\n",
            "Epoch: 6, Train loss: 0.249, Val loss: 2.310, Epoch time = 45.485s\n",
            "Epoch: 7, Train loss: 0.231, Val loss: 2.364, Epoch time = 45.259s\n",
            "Epoch: 8, Train loss: 0.217, Val loss: 2.387, Epoch time = 46.500s\n",
            "Epoch: 9, Train loss: 0.204, Val loss: 2.420, Epoch time = 45.088s\n",
            "Epoch: 10, Train loss: 0.193, Val loss: 2.460, Epoch time = 46.352s\n",
            "Epoch: 11, Train loss: 0.179, Val loss: 2.474, Epoch time = 45.424s\n",
            "Epoch: 12, Train loss: 0.167, Val loss: 2.510, Epoch time = 45.361s\n",
            "Epoch: 13, Train loss: 0.159, Val loss: 2.530, Epoch time = 46.208s\n",
            "Epoch: 14, Train loss: 0.151, Val loss: 2.536, Epoch time = 45.034s\n",
            "Epoch: 15, Train loss: 0.142, Val loss: 2.543, Epoch time = 46.415s\n",
            "Epoch: 16, Train loss: 0.135, Val loss: 2.547, Epoch time = 45.300s\n",
            "Epoch: 17, Train loss: 0.129, Val loss: 2.551, Epoch time = 45.695s\n",
            "Epoch: 18, Train loss: 0.123, Val loss: 2.569, Epoch time = 46.184s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        memory = memory.to(DEVICE)\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys"
      ],
      "metadata": {
        "id": "8ZisvEtxVrFp"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ],
      "metadata": {
        "id": "Xt7UWSPZZXYr"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(translate(transformer, \"Eine Gruppe von Menschen steht vor einem Iglu .\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZP-79XSeZaXS",
        "outputId": "71eae0f3-6906-413a-cb8d-0b4c286fb16c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " A group of people standing in front of an igloo \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(translate(transformer, \"Die Leute fixieren das Dach eines Hauses.\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFzB_NS-Zc02",
        "outputId": "565bf6ac-4413-47a6-f222-7790f2cc0d7d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The people are really receives the roof of a house \n"
          ]
        }
      ]
    }
  ]
}